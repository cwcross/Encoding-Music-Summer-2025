{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e3073172",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Vaudeville: Generating Structured Data of Musical Moments\"\n",
    "author: 'Charlie Cross'\n",
    "date: 'July 10, 2025'\n",
    "\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "plotly-connected: true\n",
    "jupyter: python3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909dff3",
   "metadata": {},
   "source": [
    "# Vaudeville: Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daeef9d",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "In this notebook, we want to set up a framework to extract a list of Musical Moments from a given Vaudeville play. To do this, we: \n",
    "\n",
    "* Set up a Pydantic Basemodel defining the aspects of a Musical Moment.\n",
    "* Set up a Basemodel for a whole play (or scene) that we pass it, containing a list of Musical Moments.\n",
    "* Bind an LLM to this structured output\n",
    "* Split the play up into scenes, to have the LLM analyze one at a time\n",
    "    * With too much content at once, it begins to yield lower accuracy results\n",
    "* Feed each scene into the LLM, and group it back together into one object\n",
    "* Convert and export the final object, containing an entire play, as a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9709a",
   "metadata": {},
   "source": [
    "## Setting up the chat model and pydantic schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6e769",
   "metadata": {},
   "source": [
    "Here, we use gpt-4o as our model, because this is a fairly complex task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f69d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcd67f",
   "metadata": {},
   "source": [
    "The \"Description\" field is what the LLM uses to find each variable within a scene. For each variable, we want to tell it *what it is*, and *where to find it*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "334c7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class MusicalMoment(BaseModel):\n",
    "    \"\"\"Many of these musical moments reuse some preexisting (and often well-known)  melody or tune.  These are variously called \"melodie”, or “air”, and identified with a short title that refers in some way to an opera or collection of melodies from which it was drawn.  The titles might include the names of works, or other characters in those original works. In the context of the plays, these tunes become the vehicle for newly composed lyrics, which are normally rhymed, and which normally follow the poetic scansion and structure of the original lyrics.  Rhyme, versification and structure are thus of interest to us.\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number in which this musical moment takes place. Will be labeled at the top of the act or scene in which it takes place.\")\n",
    "    scene: int = Field(description=\"The scene number in which the musical moment takes place. Will be labeled at the top of the scene.\")\n",
    "    number: int = Field(description = \"The index of the musical moment in the scene. For example, if this is the first musical moment in the scene, this should be 1.\")\n",
    "    characters: list[str] = Field(description=\"the character or characters who are singing (or otherwise making music) within this specific musical moment,\")\n",
    "    dramatic_situation: str = Field(description=\"the dramatic situation (a love scene, a crowd scene) in which the musical moment is occurring\")\n",
    "    air_or_melodie: str = Field(description=\"The title of the 'air' or 'melodie' of which the musical moment is based. It will be labeled in the text as 'air' or 'melodie'.\")\n",
    "    poetic_text: str = Field(description=\"The text from the music number. Do not include stage directions, only the lyrics sung by the characters in this musical moment\")\n",
    "    rhyme_scheme: str = Field(description = \"The rhyme scheme for the poetic text in the musical moment. For example, sentences that end in 'tree' 'be' 'why' and 'high' would have a rhyme scheme of AABB.\")\n",
    "    poetic_form: str = Field(description=\"form of the poetic text, which might involve some refrain\")\n",
    "    end_of_line_accents: list[str] = Field(description = \"the end accent for each line (masculine or féminine)\")\n",
    "    syllable_count_per_line: list[int] = Field(description = \"the number of syllables per line. look out for contractions and colloquialisms.that might make the count of syllables less than obvious. Normally a word like ‘voilà’ would of course have 2 syllables. But the musical rhythm of a particular melodie might require that it be _sung_ as only one syllable, as would be the case if the text reads ‘v’la’. Similarly ‘mademoiselle’ would have 4 syllables in spoken French. But the musical context might make it sound like 5. Or a character speaking dialect might sing “Mam’zelle”, which would have only 2 (or perhaps 3) syllables.\")\n",
    "    irregularities: Optional[str] = Field(description=\"any irregularities within the musical number\")\n",
    "    stage_direction_or_cues: Optional[str] = Field(description=\"any stage directions, which tell a character what to do, but aren't a part of another character's dialogue. These are usually connected with a character’s name, and often are in some contrasting typography (italics, or in parentheses - though this may not be picked up by the filereader).  Sometimes these directions even happen in the midst of a song! In a related way there are sometimes ‘cues’ for music, or performance (as when there is an offstage sound effect, or someone is humming) Most times the stage directions appear just before or after the song text. But sometimes they appear in the midst of the texts. The directions should be reported here and not in the transcription of the poem.\")\n",
    "    reprise: Optional[str] = Field(description=\"there are sometimes directions that indicate the ‘reprise’ of some earlier number or chorus.\")\n",
    "    \n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(MusicalMoment)\n",
    "\n",
    "# structured_llm.invoke(\"Create a musical moment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82edf63",
   "metadata": {},
   "source": [
    "Below is the datatype it will return for each scene/play - a list of Musical Moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caee9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaudevillePlay(BaseModel):\n",
    "    musicalMoments: list[MusicalMoment] = Field(description=\"\"\"A list of musical moments in a Vaudeville play, as MusicalMoment objects. Many of these musical moments reuse some preexisting (and often well-known)  melody or tune.  These are variously called \"melodie”, or “air”, and identified with a short title that refers in some way to an opera or collection of melodies from which it was drawn.  The titles might include the names of works, or other characters in those original works. In the context of the plays, these tunes become the vehicle for newly composed lyrics, which are normally rhymed, and which normally follow the poetic scansion and structure of the original lyrics.  Rhyme, versification and structure are thus of interest to us.\"\"\")\n",
    "    \n",
    "\n",
    "structured_llm = llm.with_structured_output(VaudevillePlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd50ad2a",
   "metadata": {},
   "source": [
    "Here, we define the system prompt. We include a sentence about file readers missing spaces and breaking lines, so that the LLM knows to look out for it. We have found that the LLM is highly effective in correcting these inaccuracies if we mention them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a literary analyst specializing in French Vaudeville plays from the 19th century. \n",
    "Your goal is to identify each musical moment in the text, and for each, extract detailed structured information, \n",
    "including act, scene, characters, dramatic situation, air or melodie, poetic text, rhyme scheme, poetic form, end-of-line accents, syllable count, and any irregularities. \n",
    "Some parts of the text were slightly misinterpreted by the file reader (e.g., missing spaces or strange line breaks).\n",
    "\"\"\"\n",
    "human_prompt = \"\"\"\n",
    "Given the following chunk of the play, analyze and return the musical moments as a structured VaudevillePlay object.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5480d0",
   "metadata": {},
   "source": [
    "### Basic Test Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff43a6c",
   "metadata": {},
   "source": [
    "Here, we simply feed it a scene to see what it pulls out. The code is commented out to ensure it isn't accidentally run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moments = structured_llm.invoke(r\"\"\"Analyze the musical moment within the chunk of this Vaudeville play. Some parts of the text were slightly misinterpreted by the filereader, especially missing spaces. Here is the text from the play:\n",
    "                      \n",
    "#                       ACTE I, SCÈNE VI. 11\n",
    "# DERBIGNY.\n",
    "# Elle n'est pasassezmontante, puisqu'il fautvousdirelemot.\n",
    "# (Pendantcequi suit, Paulinevaaufondetmetsonchapeau.)\n",
    "# PAMELA.\n",
    "# Onlesporte comme ça... voyez, moi?... ça avantage. (Elle\n",
    "# ouvresonchâle.)\n",
    "# DERBIGNY,sévèrement.\n",
    "# C'estimmodeste, mademoiselle...Jevouspried'y ajouterquel\n",
    "# quesmillimètres...\n",
    "# PAMELA.\n",
    "# Commevousvoudrez; chacun son goût... maisvousavez tort.\n",
    "# DERBIGNY, sévèrement.\n",
    "# Mademoiselle...jevous prie d'y ajouter quelquesmillimètres!\n",
    "# PAMELA.\n",
    "# Nevousfâchez pas... je la ferai montante jusqu'au boutdu\n",
    "# nez... qu'est-cequeçamefait?\n",
    "# AIR:Desommeillerencor, machère.\n",
    "# Dubongoût,jen'suispasl'enn'mie,\n",
    "# Maisçam'estbien égal,mafoi!\n",
    "# Ens'env'loppantcommeun' momie,\n",
    "# Mam'zelleyperdraplusquemoi;\n",
    "# J'respectevosscrupul'sbarbares,\n",
    "# Maisjetiensàmesopinions;\n",
    "# Etjedéteste lesavares\n",
    "# Quicachentleursnapoléons.\n",
    "# (Elleremonte.)\n",
    "# DERBIGNY.\n",
    "# Eh bien! etPauline?...tuneluisouhaitespaslebonjour?\n",
    "# ISIDORE.\n",
    "# Si, monpapa...\n",
    "# PAULINE, quiaredescendu lascène, etd'un tonrailleur.\n",
    "# Oh! moi, j'ail'habitude d'ètreoubliée d'Isidore... Il metraite\n",
    "# enamie...Je necomptepas.\n",
    "# ISIDORE, allantàPauline.\n",
    "# Bonjour,Pauline...* (RegardantPaméla.)Elleestencoremieux\n",
    "# deprès.\n",
    "# PAMELA, àpart.\n",
    "# Qu'est-cequ'iladonc àmeregarder, ce petit?(Haut.)Etcette\n",
    "# robe, mademoiselle?\n",
    "# PAULINE\n",
    "# Là, dansma chambre.\n",
    "# FAMELA.\n",
    "# Ça sera fait endeuxtemps...J'ai aissé del'étoffe endedans.\n",
    "# (Eileentredanslachambrededroitetroisièmeplan.)\n",
    "# *Derbigny,Pauline,Isidore;Pamélaausecond plan.\n",
    "# 12 UN DOCTEUR EN HERBE.\n",
    "# ISIDORE, àpart, désolé.\n",
    "# Oh!...elles'enva!...*\n",
    "# DERBIGNY.\n",
    "# Ah!ça, avantderetourneràBriare, nous avons quelques em-\n",
    "# plettesàfaire,offretonbras à Pauline. (Bas, enpassantderrière\n",
    "# lui.)Tuferastapaixenroute*.\n",
    "# ISIDORE,embarrassé.\n",
    "# Monpapa... c'estque...\n",
    "# DERBIGNY.\n",
    "# Quoiencore?\n",
    "# ISIDORE.\n",
    "# C'estdemainl'examen.\n",
    "# DERBIGNY.\n",
    "# Nem'as-tupasditqueta compositionestfaite?\n",
    "# ISIDORE.\n",
    "# Oui, papa, oui... maison croitêtreprêt, et puis... il arrive...\n",
    "# vouscomprenez...\n",
    "# DERBIGNY.\n",
    "# Pastrop!\n",
    "# PAULINE,riant.\n",
    "# MonDieu, Isidore, que vous avezl'airdrôle!.. Dites donctout\n",
    "# desuitequevousavezbesoinderevoirvotretravail….. noussorti-\n",
    "# ronsbiensans vous...Onnevous envoudrapas...\n",
    "# ISIDORE.\n",
    "# Oh! merci, mademoisellePauline!\n",
    "# PAULINE.\n",
    "# Iln'y apasdequoi, allez!\n",
    "# DERBIGNY.\n",
    "# Queneledisais-tu?...le devoir avanttout. (Ildonnelebrasà\n",
    "# Pauline.)\n",
    "# ELBMESNE.\n",
    "# AIR: DeLuciede Lamermoor***.\n",
    "# Allons,courageetpersévère;\n",
    "# Soisbienattentif, etdemain,\n",
    "# Avecsuccès, oui,je l'espère,\n",
    "# Tupasserastonexamen.\n",
    "# ISIDORE.\n",
    "# Jetrembleetjemedésespère,\n",
    "# Quandjesongequec'est demain\n",
    "# Que,devantunjugesévère,\n",
    "# Jedoispassermonexamen.\n",
    "# PAULINE.\n",
    "# Jevoisce quiledésespère,\n",
    "# Quandjesongequec'estdemain\n",
    "# Que,devantunjugesévère,\n",
    "# Ildoitpassersonexamen.\n",
    "# *Pauline, Derbigny, Isidore.\n",
    "# **Pauline, Isidore, Derbigny.\n",
    "# ***Pauline,Derbigny,Isidore,\n",
    "#                       \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed922ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act', 1)\n",
      "('scene', 6)\n",
      "('characters', ['Pamela', 'Derbigny'])\n",
      "('dramatic_situation', 'Derbigny is reprimanding Pamela for her immodest dressing style while she defends her fashion choice.')\n",
      "('air_or_melodie', 'De sommeiller encor, ma chère')\n",
      "('poetic_text', \"Dubon goût, je n'suis pas l'enn'mie, Mais çam'est bien égal, ma foi! En s'env'loppant comme un' momie, Mam'zelle yperdr'a plusque moi; J'respecte vos scrupul's barbares, Mais je tiens à mes opinions; Et je déteste les avares Qui cachent leurs napoléons.\")\n",
      "('rhyme_scheme', 'ABABCDCD')\n",
      "('poetic_form', 'Verse with alternating rhymes, addressing the situation at hand.')\n",
      "('end_of_line_accents', ['feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'masculine'])\n",
      "('syllable_count_per_line', [12, 8, 12, 8, 12, 8, 12, 8])\n",
      "('irregularities', None)\n",
      "\n",
      "\n",
      "('act', 1)\n",
      "('scene', 6)\n",
      "('characters', ['Isidore', 'Pauline', 'Derbigny'])\n",
      "('dramatic_situation', 'Pauline encourages Isidore to focus on his exam while Derbigny offers practical advice.')\n",
      "('air_or_melodie', 'De Lucia de Lammermoor')\n",
      "('poetic_text', \"Allons, courage et persévère; Sois bien attentif, et demain, Avec succès, oui, je l'espère, Tu passeras ton examen. Isidore: Je tremble et je me désespère, Quand je songe que c'est demain Que, devant un juge sévère, Je dois passer mon examen. Pauline: Je vois ce qui le désespère, Quand je songe que c'est demain Que, devant un juge sévère, Il doit passer son examen.\")\n",
      "('rhyme_scheme', 'ABAB CDCD EFEF GHG')\n",
      "('poetic_form', 'Repetitive refrain, with alternating rhymes, echoing a supportive entourage before an exam.')\n",
      "('end_of_line_accents', ['feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'feminine', 'masculine', 'feminine', 'feminine', 'masculine', 'feminine', 'feminine'])\n",
      "('syllable_count_per_line', [12, 8, 12, 8, 12, 8, 12, 8, 12, 8, 12, 8])\n",
      "('irregularities', None)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for musicalMoment in moments.musicalMoments:\n",
    "    for attribute in musicalMoment:\n",
    "        print(attribute)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157dca0f",
   "metadata": {},
   "source": [
    "Our Pydantic object is working, and it did a good job at extracting the requested information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c93d216",
   "metadata": {},
   "source": [
    "## Loading Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55d4f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\charl\\AppData\\Local\\Temp\\ipykernel_6888\\2254834301.py:21: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  page.metadata['source'] = page.metadata['source'].replace(\"C:\\\\Users\\\\charl\\\\Documents\\\\VSCode\\\\Vaudeville\\\\Files\\PDFs\\\\\",\"\")\n"
     ]
    }
   ],
   "source": [
    "# Setting up pdf loading\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "async def loadPDF(filepath: str) -> list:\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    pages = []\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)   \n",
    "    return pages\n",
    "\n",
    "source = await loadPDF(\"Files/PDFs/La_Dette_d_honneur.pdf\")\n",
    "\n",
    "for page in source:\n",
    "        page.metadata['source'] = page.metadata['source'].replace(\"Vaudeville/Files/PDFs/\",\"\")\n",
    "\n",
    "source_content = \"\"\n",
    "for page in source:\n",
    "    source_content += page.page_content\n",
    "source_full = Document(page_content = source_content, metadata = source[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_full.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6606bda",
   "metadata": {},
   "source": [
    "## Converting a play into scene chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde66d10",
   "metadata": {},
   "source": [
    "A few possible approaches here:\n",
    "* Run a basic script to split the string at \"Acte\" or \"Scene\" (regex)\n",
    "    * We may have to clean the inputted file first. This could be done with a cheap llm call to gpt-4o-mini.\n",
    "* Use a semantic splitter, which should roughly get everything right because content should be noticeably different between scenes in general. \n",
    "    * It could mess a few things up, including splitting in the middle of a musical moment\n",
    "* Have the \"cleaning\" llm call also split by act and scene \n",
    "    * Unsuccessful approach: Having it return the start and end characters of the acts.\n",
    "    * Successful approach: Have a smaller LLM model look through the play and return a list of scene headers as they appear. Then, use regex splitting to get one scene at a time.\n",
    "\n",
    "We included 2 approaches. The first is an example of what not to do - included for pedagogical purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3761b219",
   "metadata": {},
   "source": [
    "### First approach - did not work: Character indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33192cf6",
   "metadata": {},
   "source": [
    "In this approach, we attempt to have an LLM find the start and end character counts of each scene. This did not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7712ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "processing_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478d688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Scene(BaseModel):\n",
    "    \"\"\"A single scene from from a Vaudeville play\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number. Will be labeled at the top of the act or scene in which it takes place.\")\n",
    "    scene: int = Field(description=\"The scene number within the act. Will be labeled at the top of the scene. For example, if it is Act 3 Scene 2, this value should be 2.\")\n",
    "    start_character_number: int = Field(description=\"In terms of the entire document, what is the index of the first character of the scene, including the label of the scene, and act if mentioned next to the scene number (mostly only applicable if scene 1 of an act). For example, if the whole document was 'Play 1: Title. Act 1, Scene 2. Content.' then the start index would be 15, since 'Act' starts on the 16th character.\")\n",
    "    end_character_number: int = Field(description=\"In terms of the entire document, the index of the last character of the scene. It should be the last character before the next scene or act is labeled.\")\n",
    "\n",
    "class FullPlay(BaseModel):\n",
    "    \"\"\"A full play, that has yet to be broken into individual scenes.\"\"\"\n",
    "\n",
    "    all_scenes: List[Scene] = Field(description=\"A list of every single scene's start and end - each as a Scene object containing indexes and the first and last character, so that it can easily be passed into a substring just containing the scene.\")\n",
    "\n",
    "formatted_splitter_llm = processing_llm.with_structured_output(FullPlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8559b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_play(doc):\n",
    "    response = formatted_splitter_llm.invoke(f\"The following is a Vaudeville play in French. Your job is to return the necessary indexes required to split it up into individual scenes. Thus, you will be looking for 'Acte' and 'Scène' throughout the text. For each scene, you will document the act, scene number (ex Act 4, Scene 1), start character index, and end character index as a Scene object, then add it to the list of scenes in the FullPlay object. All start and end indexes should be in terms of the full document; the goal is to create a substring using FullText[start_index:end_index] for each scene. After you've gone through the full document, you will return the FullPlay object.\\n\\nPlay Content:\\n{doc.page_content}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e903ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indexes = split_up_play(source_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4e173",
   "metadata": {},
   "source": [
    "Upon looking into the result, it was clearly incorrect. Thus, we tried another approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2ac1c",
   "metadata": {},
   "source": [
    "### Second Approach: Scene Headers and Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ca40d9",
   "metadata": {},
   "source": [
    "Here, we have the LLM return the scene headers as they appear in the text. Then, we split on these headers.\n",
    "\n",
    "This is not perfect and a few headers are always missed, but it works well enough to split up the text into manageable chunks for the app. It also guarantees a split cannot occur in the middle of a scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "processing_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f5fc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Scene(BaseModel):\n",
    "    \"\"\"A single scene from a Vaudeville play\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number or label as it appears in the text.\")\n",
    "    scene: int = Field(description=\"The scene number or label as it appears in the text.\")\n",
    "    header: str = Field(description=\"The exact scene header line, copied verbatim from the text.\")\n",
    "\n",
    "class FullPlay(BaseModel):\n",
    "    \"\"\"A full play, that has yet to be broken into individual scenes.\"\"\"\n",
    "\n",
    "    all_scenes: List[Scene] = Field(description=\"A list of every single scene's header and label - each as a Scene object.\")\n",
    "\n",
    "formatted_splitter_llm = processing_llm.with_structured_output(FullPlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44147c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "The following is the full text of a French Vaudeville play. Your job is to identify every scene boundary.\n",
    "For each scene, return:\n",
    "- The act number (as it appears in the text)\n",
    "- The scene number (as it appears in the text)\n",
    "- The exact scene header line (copy it verbatim from the text)\n",
    "\n",
    "Return a list of objects like:\n",
    "{{\"act\": \"...\", \"scene\": \"...\", \"header\": \"...\"}}\n",
    "\n",
    "Do not attempt to count character indexes. Only return the scene headers as they appear in the text.\n",
    "\n",
    "Play Content: \\n\n",
    "{source_full.page_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fed7c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_play(doc):\n",
    "    response = formatted_splitter_llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c481a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indexes = split_up_play(source_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c20271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act 1, Scene 1 Header: Scène première\n",
      "Act 1, Scene 2 Header: Scène II\n",
      "Act 1, Scene 3 Header: Scène III\n",
      "Act 1, Scene 4 Header: Scène IV\n",
      "Act 1, Scene 5 Header: Scène V\n",
      "Act 1, Scene 6 Header: Scène VI\n",
      "Act 1, Scene 7 Header: Scène VII\n",
      "Act 1, Scene 8 Header: Scène VIII\n",
      "Act 1, Scene 9 Header: Scène IX\n",
      "Act 2, Scene 1 Header: Scène première\n",
      "Act 2, Scene 2 Header: Scène II\n",
      "Act 2, Scene 3 Header: Scène III\n",
      "Act 2, Scene 4 Header: Scène IV\n",
      "Act 2, Scene 5 Header: Scène V\n",
      "Act 2, Scene 6 Header: Scène VI\n",
      "Act 2, Scene 7 Header: Scène VII\n",
      "Act 2, Scene 8 Header: Scène VIII\n"
     ]
    }
   ],
   "source": [
    "scenes: List[Scene] = all_indexes.all_scenes\n",
    "for i,scene in enumerate(scenes):\n",
    "    print (f\"\"\"Act {scene.act}, Scene {scene.scene} Header: {scene.header}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "853a5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "all_splits = []\n",
    "scene_headers = all_indexes.all_scenes\n",
    "full_text = source_full.page_content\n",
    "\n",
    "prev_end_idx = 0\n",
    "for i, scene in enumerate(scene_headers):\n",
    "    # Find the start index of this scene's header after the previous end index\n",
    "    start_idx = full_text.find(scene.header, prev_end_idx)\n",
    "    if start_idx == -1:\n",
    "        raise ValueError(f\"Scene header not found: {scene.header}\")\n",
    "\n",
    "    # Determine the end index: start of next scene header, or end of document\n",
    "    if i + 1 < len(scene_headers):\n",
    "        next_start_idx = full_text.find(scene_headers[i + 1].header, start_idx + len(scene.header))\n",
    "        if next_start_idx == -1:\n",
    "            end_idx = len(full_text)\n",
    "        else:\n",
    "            end_idx = next_start_idx\n",
    "    else:\n",
    "        end_idx = len(full_text)\n",
    "\n",
    "    scene_text = full_text[start_idx:end_idx]\n",
    "    doc = Document(page_content=scene_text, metadata={\"act\": scene.act, \"scene\": scene.scene, \"header\": scene.header})\n",
    "    all_splits.append(doc)\n",
    "    prev_end_idx = end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8fe34",
   "metadata": {},
   "source": [
    "Upon looking into the result, it was fairly accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae8eea",
   "metadata": {},
   "source": [
    "## Setting up the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb432049",
   "metadata": {},
   "source": [
    "Here, we set up a basic LangGraph sequence. This specific version of the app uses indexes to go the list of scenes, and is thus called with a for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7042612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"human\",\"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "     ])\n",
    "\n",
    "class State(TypedDict):\n",
    "    index: int\n",
    "    context: Document\n",
    "    answer: str\n",
    "\n",
    "def check_index(state: State):\n",
    "    if \"index\" in state and isinstance(state[\"index\"], int) and 0 <= state[\"index\"] < len(all_indexes):\n",
    "        return state \n",
    "    raise ValueError(\"Need to include an index for list of documents.\") \n",
    "\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    document = all_indexes[state[\"index\"]]\n",
    "    return {\"context\": document}\n",
    "\n",
    "def generate(state: State):\n",
    "    message = prompt.invoke({\"question\":human_prompt,\"context\":state[\"context\"].page_content})\n",
    "    response = structured_llm.invoke(message)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([check_index, retrieve_doc, generate])\n",
    "graph_builder.add_edge(START, \"check_index\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdba6eb",
   "metadata": {},
   "source": [
    "## Loading a Single Scene / PDF to Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97dd656",
   "metadata": {},
   "source": [
    "Here, we load one scene. We had to customize our sequence for this specific test (), so the code 2 cells below is mostly a duplicate of the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_test = await loadPDF(\"Vaudeville/Tests and Outputs/Scene_1_La_Dette_d_honneur.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe51c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "scene_test_full = \"\"\n",
    "for page in scene_test:\n",
    "    scene_test_full += page.page_content\n",
    "scene_test_final = Document(page_content = scene_test_full)\n",
    "all_indexes = [scene_test_final]\n",
    "\n",
    "\n",
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"human\",\"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "     ])\n",
    "\n",
    "class State(TypedDict):\n",
    "    index: int\n",
    "    context: Document\n",
    "    answer: str\n",
    "\n",
    "def check_index(state: State):\n",
    "    if \"index\" in state and isinstance(state[\"index\"], int) and 0 <= state[\"index\"] < len(all_indexes):\n",
    "        return state \n",
    "    raise ValueError(\"Need to include an index for list of documents.\") \n",
    "\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    document = all_indexes[state[\"index\"]]\n",
    "    return {\"context\": document}\n",
    "\n",
    "def generate(state: State):\n",
    "    message = prompt.invoke({\"question\":human_prompt,\"context\":state[\"context\"].page_content})\n",
    "    response = structured_llm.invoke(message)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([check_index, retrieve_doc, generate])\n",
    "graph_builder.add_edge(START, \"check_index\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b5960fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = graph.invoke({\"index\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "598473f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "moment = moments[\"answer\"].musicalMoments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d504e843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('act', 1)\n",
      "('scene', 1)\n",
      "('number', 1)\n",
      "('characters', ['Pétronille'])\n",
      "('dramatic_situation', 'Pétronille is recounting to Pauline how two young men, believed to be lovers, rented a room from her aunt.')\n",
      "('air_or_melodie', 'De sommeiller encor, ma chère')\n",
      "('poetic_text', 'Lorsqu’arrivés un jour par aventure,\\nIls vinr’nt chez nous pour se loger tous deux ;\\nOn vit tout d’suite à leur figure,\\nQu’ça d’vait être des amoureux.\\nPour qu’à leur gré tous les instants s’écoulent,\\nMa tant’ s’est dit : ils s’raient mal au premier ;\\nEt nuit et jour puisqu’ils roucoulent,\\nJ’ m’en vas les mettre au colombier.')\n",
      "('rhyme_scheme', 'ABAB CDCD')\n",
      "('poetic_form', 'Quatrains')\n",
      "('end_of_line_accents', ['feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'masculine'])\n",
      "('syllable_count_per_line', [13, 10, 9, 8, 11, 10, 10, 8])\n",
      "('irregularities', None)\n",
      "\n",
      "\n",
      "('act', 1)\n",
      "('scene', 1)\n",
      "('number', 2)\n",
      "('characters', ['Pétronille'])\n",
      "('dramatic_situation', 'Pétronille describes a visit to Paris and seeing a local girl, Madeleine, who has become a limonadière at a famous café.')\n",
      "('air_or_melodie', 'L’autre jour la petite Isabelle')\n",
      "('poetic_text', 'Sur la tête elle a d’ bell’s panaches,\\nAl’ porte un’ rob’ couverte d’ fleurs ;\\nOn voit d’ beaux messieurs à moustaches,\\nQui vienn’nt lui conter des douceurs ;\\nSans jamais prendr’ ses airs maussades,\\nEll’ distribue aux amateurs,\\nDes limonades\\nEt des œillades\\nEt des liqueurs.')\n",
      "('rhyme_scheme', 'ABAB CDDDEE')\n",
      "('poetic_form', 'Sixain followed by tercet')\n",
      "('end_of_line_accents', ['feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'masculine', 'feminine', 'feminine', 'masculine'])\n",
      "('syllable_count_per_line', [12, 9, 10, 9, 10, 9, 5, 5, 5])\n",
      "('irregularities', None)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moments = moments[\"answer\"]\n",
    "for musicalMoment in moments.musicalMoments:\n",
    "    for attribute in musicalMoment:\n",
    "        print(attribute)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bee0d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL PLAY\n",
    "moments = graph.invoke({\"index\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "moments = moments[\"answer\"]\n",
    "for musicalMoment in moments.musicalMoments:\n",
    "    for attribute in musicalMoment:\n",
    "        print(attribute)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea51468",
   "metadata": {},
   "source": [
    "The output has been removed because of it's length. The test was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122a66d",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## Full Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68705084",
   "metadata": {},
   "source": [
    "Below, we have grouped the full workflow into one large sequence. Thus, you can change the pdf_filepath variable, hit run all below, and a csv will be exported into your directory. Most of the code below is the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477fe23",
   "metadata": {},
   "source": [
    "### Loading the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7f5c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hit execute cells below once you add your pdf_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed204a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_filepath = \"Files/PDFs/Scribe-Cornu_-_La_chanoinesse.pdf\"\n",
    "csv_filename = pdf_filepath.replace(\"Files/PDFs/\",\"\").replace(\".pdf\",\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05edd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up pdf loading\n",
    "\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PDFPlumberLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "async def loadPDF(filepath: str) -> list:\n",
    "    loader = PyPDFLoader(filepath)\n",
    "    pages = []\n",
    "    async for page in loader.alazy_load():\n",
    "        pages.append(page)   \n",
    "    return pages\n",
    "\n",
    "# filepath:str = input(\"Please enter the filepath: \")\n",
    "source = await loadPDF(pdf_filepath)\n",
    "\n",
    "for page in source:\n",
    "        page.metadata['source'] = page.metadata['source'].replace(\"Files\\PDFs\\\\\",\"\")\n",
    "\n",
    "source_content = \"\"\n",
    "for page in source:\n",
    "    source_content += page.page_content\n",
    "source_full = Document(page_content = source_content, metadata = source[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107d458",
   "metadata": {},
   "source": [
    "### Splitting up the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b8e3962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "processing_llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b49ec5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Scene(BaseModel):\n",
    "    \"\"\"A single scene from a Vaudeville play\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number or label as it appears in the text.\")\n",
    "    scene: int = Field(description=\"The scene number or label as it appears in the text.\")\n",
    "    header: str = Field(description=\"The exact scene header line, copied verbatim from the text.\")\n",
    "\n",
    "class FullPlay(BaseModel):\n",
    "    \"\"\"A full play, that has yet to be broken into individual scenes.\"\"\"\n",
    "\n",
    "    all_scenes: List[Scene] = Field(description=\"A list of every single scene's header and label - each as a Scene object.\")\n",
    "\n",
    "formatted_splitter_llm = processing_llm.with_structured_output(FullPlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "859dc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "The following is the full text of a French Vaudeville play. Your job is to identify every scene boundary.\n",
    "For each scene, return:\n",
    "- The act number (as it appears in the text)\n",
    "- The scene number (as it appears in the text)\n",
    "- The exact scene header line (copy it verbatim from the text)\n",
    "\n",
    "Return a list of objects like:\n",
    "{{\"act\": \"...\", \"scene\": \"...\", \"header\": \"...\"}}\n",
    "\n",
    "Do not attempt to count character indexes. Only return the scene headers as they appear in the text.\n",
    "\n",
    "Play Content: \\n\n",
    "{source_full.page_content}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d88eba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_play(doc):\n",
    "    response = formatted_splitter_llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd0f744b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indexes = split_up_play(source_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "efbfe648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "all_splits = []\n",
    "scene_headers = all_indexes.all_scenes\n",
    "full_text = source_full.page_content\n",
    "\n",
    "prev_end_idx = 0\n",
    "for i, scene in enumerate(scene_headers):\n",
    "    # Find the start index of this scene's header after the previous end index\n",
    "    start_idx = full_text.find(scene.header, prev_end_idx)\n",
    "    if start_idx == -1:\n",
    "        print(f\"Scene header not found: {scene.header}\")\n",
    "\n",
    "    # Determine the end index: start of next scene header, or end of document\n",
    "    if i + 1 < len(scene_headers):\n",
    "        next_start_idx = full_text.find(scene_headers[i + 1].header, start_idx + len(scene.header))\n",
    "        if next_start_idx == -1:\n",
    "            end_idx = len(full_text)\n",
    "        else:\n",
    "            end_idx = next_start_idx\n",
    "    else:\n",
    "        end_idx = len(full_text)\n",
    "\n",
    "    scene_text = full_text[start_idx:end_idx]\n",
    "    doc = Document(page_content=scene_text, metadata={\"act\": scene.act, \"scene\": scene.scene, \"header\": scene.header})\n",
    "    all_splits.append(doc)\n",
    "    prev_end_idx = end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e8c2fb",
   "metadata": {},
   "source": [
    "### Setting up the pydantic object and LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a99e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class MusicalMoment(BaseModel):\n",
    "    \"\"\"Many of these musical moments reuse some preexisting (and often well-known)  melody or tune.  These are variously called \"melodie”, or “air”, and identified with a short title that refers in some way to an opera or collection of melodies from which it was drawn.  The titles might include the names of works, or other characters in those original works. In the context of the plays, these tunes become the vehicle for newly composed lyrics, which are normally rhymed, and which normally follow the poetic scansion and structure of the original lyrics.  Rhyme, versification and structure are thus of interest to us.\"\"\"\n",
    "\n",
    "    act: int = Field(description=\"The act number in which this musical moment takes place. Will be labeled at the top of the act or scene in which it takes place.\")\n",
    "    scene: int = Field(description=\"The scene number in which the musical moment takes place. Will be labeled at the top of the scene.\")\n",
    "    number: int = Field(description = \"The index of the musical moment in the scene. For example, if this is the first musical moment in the scene, this should be 1.\")\n",
    "    characters: list[str] = Field(description=\"the character or characters who are singing (or otherwise making music) within this specific musical moment,\")\n",
    "    dramatic_situation: str = Field(description=\"the dramatic situation (a love scene, a crowd scene) in which the musical moment is occurring\")\n",
    "    air_or_melodie: str = Field(description=\"The title of the 'air' or 'melodie' of which the musical moment is based. It will be labeled in the text as 'air' or 'melodie'.\")\n",
    "    poetic_text: str = Field(description=\"The text from the music number. Do not include stage directions, only the lyrics sung by the characters in this musical moment\")\n",
    "    rhyme_scheme: str = Field(description = \"The rhyme scheme for the poetic text in the musical moment. For example, sentences that end in 'tree' 'be' 'why' and 'high' would have a rhyme scheme of AABB.\")\n",
    "    poetic_form: str = Field(description=\"form of the poetic text, which might involve some refrain\")\n",
    "    end_of_line_accents: list[str] = Field(description = \"the end accent for each line (masculine or féminine)\")\n",
    "    syllable_count_per_line: list[int] = Field(description = \"the number of syllables per line. look out for contractions and colloquialisms.that might make the count of syllables less than obvious. Normally a word like ‘voilà’ would of course have 2 syllables. But the musical rhythm of a particular melodie might require that it be _sung_ as only one syllable, as would be the case if the text reads ‘v’la’. Similarly ‘mademoiselle’ would have 4 syllables in spoken French. But the musical context might make it sound like 5. Or a character speaking dialect might sing “Mam’zelle”, which would have only 2 (or perhaps 3) syllables.\")\n",
    "    irregularities: Optional[str] = Field(description=\"any irregularities within the musical number\")\n",
    "    stage_direction_or_cues: Optional[str] = Field(description=\"any stage directions, which tell a character what to do, but aren't a part of another character's dialogue. These are usually connected with a character’s name, and often are in some contrasting typography (italics, or in parentheses - though this may not be picked up by the filereader).  Sometimes these directions even happen in the midst of a song! In a related way there are sometimes ‘cues’ for music, or performance (as when there is an offstage sound effect, or someone is humming) Most times the stage directions appear just before or after the song text. But sometimes they appear in the midst of the texts. The directions should be reported here and not in the transcription of the poem.\")\n",
    "    reprise: Optional[str] = Field(description=\"there are sometimes directions that indicate the ‘reprise’ of some earlier number or chorus.\")\n",
    "\n",
    "class VaudevillePlay(BaseModel):\n",
    "    musicalMoments: list[MusicalMoment] = Field(description=\"\"\"A list of musical moments in a Vaudeville play, as MusicalMoment objects. Many of these musical moments reuse some preexisting (and often well-known)  melody or tune.  These are variously called \"melodie”, or “air”, and identified with a short title that refers in some way to an opera or collection of melodies from which it was drawn.  The titles might include the names of works, or other characters in those original works. In the context of the plays, these tunes become the vehicle for newly composed lyrics, which are normally rhymed, and which normally follow the poetic scansion and structure of the original lyrics.  Rhyme, versification and structure are thus of interest to us.\"\"\")    \n",
    "\n",
    "structured_llm = llm.with_structured_output(VaudevillePlay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f903d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a literary analyst specializing in French Vaudeville plays from the 18th century. \n",
    "Your goal is to identify each musical moment in the text, and for each, extract detailed structured information, \n",
    "including act, scene, characters, dramatic situation, air or melodie, poetic text, rhyme scheme, poetic form, end-of-line accents, syllable count, and any irregularities. \n",
    "Some parts of the text were slightly misinterpreted by the file reader (e.g., missing spaces or strange line breaks).\n",
    "\"\"\"\n",
    "human_prompt = \"\"\"\n",
    "Given the following chunk of the play, analyze and return the musical moments as a structured VaudevillePlay object.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31937dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import List, TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"human\",\"Context:\\n{context}\\n\\nQuestion:\\n{question}\")\n",
    "     ])\n",
    "\n",
    "class State(TypedDict):\n",
    "    index: int\n",
    "    context: Document\n",
    "    answer: str\n",
    "\n",
    "def check_index(state: State):\n",
    "    return state\n",
    "\n",
    "def retrieve_doc(state: State):\n",
    "    document = all_splits[state[\"index\"]]\n",
    "    return {\"context\": document}\n",
    "\n",
    "def generate(state: State):\n",
    "    i = state[\"index\"]\n",
    "    message = prompt.invoke({\"question\":human_prompt,\"context\" : f'Act {all_indexes.all_scenes[i].act}, Scene {all_indexes.all_scenes[i].scene}:\\n\\n {state[\"context\"].page_content}'})\n",
    "    response = structured_llm.invoke(message)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([check_index, retrieve_doc, generate])\n",
    "graph_builder.add_edge(START, \"check_index\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafbe57e",
   "metadata": {},
   "source": [
    "### Analyzing the scenes and merging them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552d3d8",
   "metadata": {},
   "source": [
    "This is the new code. It goes through each scene, calls the LangGraph, then merges all of the scenes together into one object. Then, it exports it as a csv (based on the filename of the PDF) to a csv_outputs folder in your directory. In the github repository, you can view the 7 objects I tested. Or, you can follow this [link](https://docs.google.com/spreadsheets/d/1WBVLnW_EfVwT60LsOVykd4lNaYEB0NAPvJUaMvyyBrM/edit?usp=sharing) to see the spreadsheet on Google Sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9fa8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scenes(docs: List[Document]) -> List[MusicalMoment]:\n",
    "    all_moments: List[MusicalMoment] = []\n",
    "\n",
    "    for i,doc in enumerate(docs):\n",
    "        response = graph.invoke({\"index\": i})\n",
    "        moments = response[\"answer\"].musicalMoments\n",
    "        all_moments.extend(moments)\n",
    "    \n",
    "    return all_moments\n",
    "\n",
    "all_moments = analyze_scenes(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5d26f404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Convert all MusicalMoment objects to dicts\n",
    "moments_dicts = [moment.model_dump() for moment in all_moments]\n",
    "\n",
    "# Get all field names from the first moment\n",
    "fieldnames = moments_dicts[0].keys() if moments_dicts else []\n",
    "\n",
    "# Write to CSV\n",
    "# Ensure the output folder exists\n",
    "output_folder = \"csv_outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Build the output path\n",
    "output_path = os.path.join(output_folder, os.path.basename(csv_filename))\n",
    "\n",
    "with open(output_path, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in moments_dicts:\n",
    "        # Convert lists to strings for CSV output\n",
    "        for key, value in row.items():\n",
    "            if isinstance(value, list):\n",
    "                row[key] = \"; \".join(str(v) for v in value)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25104268",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This system is highly effective, and serves as a good template for the niche that is a Structured Output App. \n",
    "\n",
    "However, some improvements are needed for this to reach its most accurate form. Most notably, the descriptions for the variable within the Pydantic schema are lacking expertise in the subject. To reach it's best form, an expert in these plays would have to write these descriptions.\n",
    "\n",
    "That being said, this system is impressive as is. Reading through all 7 Vaudeville plays (~50 pages each) only took about 20 minutes of passive run time and a few dollars with the OpenAI API. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
